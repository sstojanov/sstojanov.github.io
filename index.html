<!DOCTYPE html>
<html lang="en">
    <head>

        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-JZQDMRY8W2"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-JZQDMRY8W2');
        </script>
 
        <title>Stefan Stojanov</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="bootstrap/css/bootstrap.min.css">
        <link rel="stylesheet" type="text/css" href="main.css">
        <link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Lato">
    
    </head>
    <body>
    
        <script src="jquery-3.5.1.min.js"></script>
        <script src="bootstrap/js/bootstrap.min.js"></script>
         
        <div class="container-md my-3 border py-4">
            <div class="row align-items-center justify-content-center">

                <div class="col-md-3 px-4">
                    <div class="text-center">
                        <img src="img/me.jpg" class="img-fluid rounded-circle pb-2" alt="...">

                        <div class="text-center-fluid">
                        <h2 style="margin-bottom: 0;">Stefan Stojanov</h2>
                        <p style="margin-bottom: 0;">stojanov@stanford.edu</p>
                        <p style="margin-bottom: 5pt;"> <a href=stefan_stojanov_cv.pdf>R&#233sum&#233</a> / <a href=stefan_stojanov_cv.pdf>CV</a>  </p>
                        <p style="margin-bottom: 0;"> 
                            <a href="https://twitter.com/sstj389"><img src="img/icons/twitter-svgrepo-com.svg" height="25"></a> 
                            <a href="https://github.com/sstojanov/"><img src="img/icons/github-svgrepo-com.svg" height="25"></a> 
                            <a href="https://scholar.google.com/citations?user=XC_WricAAAAJ&hl=en"><img src="img/icons/google-scholar-svgrepo-com.svg" height="25"></a> 
                            <a href="https://www.linkedin.com/in/sstojanov/"><img src="img/icons/linkedin-svgrepo-com.svg" height="25"></a> 
                        </p>
                        </div>
                    </div>
                </div>

                <div class="col-md-7 px-4 py-4">

                    <div class="text-center">


                        <p align=justify> 
                        I am a postdoctoral researcher in the <a href="https://svl.stanford.edu/"> Stanford Vision and Learning Lab </a> and <a href="https://neuroailab.stanford.edu/"> Stanford NeuroAILab </a>, where I am advised by <a href="https://jiajunwu.com/">Jiajun Wu</a> and <a href="http://stanford.edu/~yamins/">Dan Yamins</a>. I am fortunate to be supported by a fellowship from <a href="https://hai.stanford.edu/">Stanford HAI</a>. I received my PhD at at the Georgia Institute of Technology advised by <a href="https://rehg.org/">James Rehg</a>. 
                        </p>


                        <p align=justify> 
                        My main research interests are in computer vision and machine learning. I focus on the intersection of 3D vision, self-supervision, data synthesis, and video-based learning. My work explores how these areas can complement each other to develop systems capable of efficiently learning rich, granular representations of the physical world.</p>

                        <p align=justify> 
                        <b> I am actively seeking AI-related full-time opportunities in industry. <br> Please reach out if you think I could be a good fit!</b>
                        </p>
                    
                    </div>
                    </div>

            </div>

        </div>

            <div class="container-md p-3 my-3 border">
            <h2 class="text-center">Publications</h2>

            <div class="publication">
                <div class="row justify-content-center mb-2">
                    <div class="col-auto p-0">
                        <br>
                        <img src="img/pub/thai_eccv_2024.png" class="img-fluid" alt="..." style="max-width: 150px">
                    </div>
    
                    <div class="col-8 py-4 ">
                        <p><b>3 Ã— 2: 3D Object Part Segmentation by 2D Semantic Correspondences</b><br>
                        <p>Leveraging visual correspondence from off the shelf vision foundation models for 3D part segmentation.</p>
                        <p><a href="https://anhthai1997.wordpress.com/">Anh Thai</a>, Weiyao Wang, Hao Tang, <b>Stefan Stojanov</b>, <a href="https://rehg.org/">James M. Rehg</a>, Matt Feiszli.</p>
                        <p>ECCV 2024 - poster</p>
                        <p><a href="https://arxiv.org/abs/2407.09648">paper</a>                     
                    </div>
    
            </div>
            </div>

            <hr>


            <div class="publication">
                <div class="row justify-content-center mb-2">
                    <div class="col-auto p-0">
                        <br>
                        <img src="img/pub/huang_cvpr_2024.png" class="img-fluid" alt="..." style="max-width: 150px">
                    </div>
    
                    <div class="col-8 py-4 ">
                        <p><b>ZeroShape: Regression-based Zero-shot Shape Reconstruction</b><br>
                        <p>SOTA 3D shape reconstructor with high computational efficiency and low training data budget.</p>
                        <p><a href="https://zixuanh.com/">Zixuan Huang*</a>, <b>Stefan Stojanov*</b>, <a href="https://anhthai1997.wordpress.com/">Anh Thai</a>, <a href="https://varunjampani.github.io/">Varun Jampani</a>, <a href="https://rehg.org/">James M. Rehg</a></p>
                        <p>CVPR 2024 - poster</p>
                        <p><a href="https://arxiv.org/abs/2312.14198">paper</a> / <a href="https://github.com/zxhuang1698/ZeroShape">code</a> / <a href="https://zixuanh.com/projects/zeroshape.html">project page</a> / <a href="https://huggingface.co/spaces/zxhuang1698/ZeroShape">demo</a></p>
                    </div>
    
            </div>
            </div>

            <hr>

            <div class="publication">
                <div class="row justify-content-center mb-2">
                    <div class="col-auto p-0">
                        <img src="img/pub/thai_neurips_2023.gif" class="img-fluid" alt="..." style="max-width: 150px">
                    </div>
    
                    <div class="col-8 py-0 ">
                        <p><b>Low-shot Object Learning with Mutual Exclusivity Bias</b><br>
                        <p>Mutual Exclusivity Bias enables fast learning of objects that generalizes.</p>
                        <p><a href="https://anhthai1997.wordpress.com/">Anh Thai</a>, <a href="http://ahumayun.com/">Ahmad Humayun</a>, <b>Stefan Stojanov</b>, <a href="https://zixuanh.com/">Zixuan Huang</a>, Bikram Boote, <a href="https://rehg.org/">James M. Rehg</a></p>
                        <p>NeurIPS 2023, Datasets and Benchmarks Track</p>
                        <p><a href="https://arxiv.org/abs/2312.03533">paper</a> / <a href="https://github.com/rehg-lab/LSME">code</a> / <a href="https://ngailapdi.github.io/projects/lsme/">project page</a></p>
                    </div>
    
                </div>
                </div>
    
            <hr>


            <div class="publication">
            <div class="row justify-content-center mb-2">
                <div class="col-auto p-0">
                    <img src="img/pub/huang_cvpr_2023.gif" class="img-fluid" alt="..." style="max-width: 150px">
                </div>

                <div class="col-8 py-0 ">
                    <p><b>ShapeClipper: Scalable 3D Shape Learning via Geometric and CLIP-based Consistency</b><br>
                    <p>CLIP and geometric consistency constraints facilitate scalable learning of object shape reconstruction.</p>
                    <p><a href="https://zixuanh.com/">Zixuan Huang</a>, <a href="https://varunjampani.github.io/">Varun Jampani</a>, <a href="https://anhthai1997.wordpress.com/">Anh Thai</a>, <a href="https://people.csail.mit.edu/yzli">Yuanzhen Li</a>, <b>Stefan Stojanov</b>, <a href="https://rehg.org/">James M. Rehg</a></p>
                    <p>CVPR 2023 - poster</p>
                    <p><a href="https://arxiv.org/abs/2304.06247">arxiv</a> / <a href="https://github.com/zxhuang1698/ShapeClipper">code</a> / <a href="https://zixuanh.com/projects/shapeclipper.html">project page</a> / <a href="https://www.youtube.com/watch?v=BxTGVjXoXu8">video</a> </p>
                </div>

            </div>
            </div>


            <hr>


            <div class="publication">
            <div class="row justify-content-center mb-2">
                <div class="col-auto p-0 ">
                    <img src="img/pub/stojanov_neurips_2022.png" class="img-fluid" alt="..." style="max-width: 150px">
                </div>

                <div class="col-8 py-0 ">
                    <p><b>Learning Dense Object Descriptors from Multiple Views for Low-shot Category Generalization</b><br>
                    <p>Dense feature-level self-supervised learning from multiple camera views without <br> any category labels leads to representations that can generalize to novel categories.</p>
                    <p><b>Stefan Stojanov</b>, <a href="https://anhthai1997.wordpress.com/">Anh Thai</a>, <a href="https://zixuanh.com/">Zixuan Huang</a>, <a href="https://rehg.org/">James M. Rehg</a></p>
                    <p>NeurIPS 2022 - Poster</p>
                    <p><a href="https://arxiv.org/abs/2211.15059">arxiv</a> / <a href="https://github.com/rehg-lab/dope_selfsup">code</a> / <a href="https://sstojanov.github.io/projects/dope_selfsup.html">project page</a> / <a href="https://sstojanov.github.io/assets/neurips2022/poster.pdf">poster</a> / <a href="https://www.youtube.com/watch?v=qaArkLiiymkv">video</a> </p>
                    <!--<p>arxiv / code / project page</p>-->
                </div>

            </div>
            </div>

            <hr>

            <div class="publication">
            <div class="row justify-content-center mb-2">
                <div class="col-auto p-0">
                    <img src="img/pub/huang_eccv_2022.jpg" class="img-fluid" style="max-width: 150px" alt="...">
                </div>

                <div class="col-8 py-2 ">
                    <p><b>Planes vs. Chairs: Category-guided 3D shape learning without any 3D cues</b></a><br>
                    <p>A 3D-unsupervised model that learn shapes of multiple object categories at once.</p>
                    <p><a href="https://zixuanh.com/">Zixuan Huang</a>, <b>Stefan Stojanov</b>, <a href="https://anhthai1997.wordpress.com/">Anh Thai</a>, <a href="https://varunjampani.github.io/">Varun Jampani</a>, <a href="https://rehg.org/">James M. Rehg</a></p>
                    <p>ECCV 2022 - Poster</p>
                    <p><a href="https://arxiv.org/abs/2204.10235">arxiv</a> / <a href="https://github.com/zxhuang1698/cat-3d">code</a> / <a href="https://zixuanh.com/eccv2022-multiclass3D.html">project page</a> / <a href=https://zixuanh.com/eccv2022-multiclass3D/4231.pdf>poster</a> / <a href=https://zixuanh.com/eccv2022-multiclass3D/4231.mp4">video</a></p>
                </div>

            </div>
            </div>

            <hr>

            <div class="publication">
            <div class="row justify-content-center mb-2">
                <div class="col-auto p-0">
                    <img src="img/pub/thai_3dv_2022.png" class="img-fluid" style="max-width: 150px" alt="...">
                </div>

                <div class="col-8 py-0 ">
                    <p><b>The Surprising Positive Knowledge Transfer in Continual 3D Object Shape Reconstruction</b></a><br>
                <p>Continual learning of 3D shape reconstruction does not suffer from catastrophic <br> forgetting as much as discriminative learning tasks.</p>
                    <p><a href="https://anhthai1997.wordpress.com/">Anh Thai</a>, <b>Stefan Stojanov</b>, <a href="https://zixuanh.com/">Zixuan Huang</a>, <a href="https://rehg.org/">James M. Rehg</a></p>
                    <p>3DV 2022 - Poster</p>
                    <p><a href="https://arxiv.org/abs/2101.07295">arxiv</a> / <a href="https://github.com/rehg-lab/CLRec">code</a> 
                </div>

            </div>
            </div>

            <hr>

            <div class="publication">
            <div class="row justify-content-center mb-2">
                <div class="col-auto p-0">
                    <img src="img/pub/stojanov_etra_2022.png" class="img-fluid" style="max-width: 150px" alt="...">
                </div>

                <div class="col-8 py-0 ">
                    <p><b>The Benefits of Depth Information for Head-Mounted Gaze Estimation</b></a><br>
                    <p>Fusing depth and image information improves deep models' robustness <br> to fitment and slip for head mounted gaze estimation</p>
                    <p><b>Stefan Stojanov</b>, <a href="https://scholar.google.com/citations?user=Tz_jwsQAAAAJ&hl=en">Sachin Talathi</a>, <a href="https://scholar.google.com/citations?user=18fTep8AAAAJ&hl=en">Abhishek Sharma</a></p>
                    <p>ETRA 2022 - Short Paper</p>
                    <p><a href="https://dl.acm.org/doi/pdf/10.1145/3517031.3529638">pdf</a>  
                </div>

            </div>
            </div>

            <hr>

            <div class="publication">
            <div class="row justify-content-center mb-2">
                <div class="col-auto p-0">
                    <img src="img/pub/stojanov_cvpr_2021.png" class="img-fluid" style="max-width: 150px" alt="...">
                </div>

                <div class="col-8 py-0 ">
                    <p><b>Using Shape to Categorize: Low-Shot Learning with an Explicit Shape Bias</b></a><br>
                    <p>Learning representations to generalize based on 3D shape and then learning <br> to map images into them leads to improved low-shot generalization.</p>
                    <p><b>Stefan Stojanov</b>, <a href="https://anhthai1997.wordpress.com/">Anh Thai</a>, <a href="https://rehg.org/">James M. Rehg</a></p>
                    <p>CVPR 2021 - Poster</p>
                    <p><a href="https://arxiv.org/abs/2101.07296">arxiv</a> / <a href="https://rehg-lab.github.io/publication-pages/lowshot-shapebias/">code</a> / <a href="https://github.com/rehg-lab/lowshot-shapebias/tree/main/toys4k">dataset</a> / <a href="https://rehg-lab.github.io/publication-pages/lowshot-shapebias/">project page</a> </p>
                </div>

            </div>
            </div>

            <hr>

            <div class="publication">
            <div class="row justify-content-center mb-2">
                <div class="col-auto p-0">
                    <img src="img/pub/thai_3dv_2021.png" class="img-fluid" style="max-width: 150px" alt="...">
                </div>

                <div class="col-8 py-0 ">
                    <p><b>3D Reconstruction of Novel Object Shapes from Single Images</b></a><br>
                    <p>An implicit SDF representation-based method for single view 3D shape reconstruction</p>
                    <p><a href="https://anhthai1997.wordpress.com/">Anh Thai</a>*, <b>Stefan Stojanov</b>*, <a href="https://rehg.org/">James M. Rehg</a></p>
                    <p>3DV 2021 - Oral</p>
                    <p><a href="https://arxiv.org/abs/2006.07752">arxiv</a> / <a href="https://github.com/rehg-lab/3DShapeGen">code</a> / <a href="https://devlearning-gt.github.io/3DShapeGen/">project page</a> </p>
                </div>

            </div>
            </div>

            <hr>

            <div class="publication">
            <div class="row justify-content-center mb-2">
                <div class="col-auto p-0">
                    <img src="img/pub/stojanov_cvpr_2019.png" class="img-fluid" style="max-width: 150px" alt="...">
                </div>

                <div class="col-8 py-0 ">
                    <p><b>Incremental Object Learning from Contiguous Views</b></a><br>
                    <p>Repetition of learned concepts in continual learning ameliorates catastrophic forgettng.</p>
                    <p><b>Stefan Stojanov</b>, <a href="https://anhthai1997.wordpress.com/">Anh Thai</a>*, <a href="https://scholar.google.com/citations?user=Vxk4TM4AAAAJ&hl=en">Samarth Mishra</a>*, <a href="https://rehg.org/">James M. Rehg</a></p>
                    <p>CVPR 2019 - Oral - <b>Best paper award finalist</b></p>
                    <p><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Stojanov_Incremental_Object_Learning_From_Contiguous_Views_CVPR_2019_paper.pdf">pdf</a> / <a href="https://github.com/iolfcv/experiments">code</a> / <a href="https://github.com/iolfcv/CRIB_Data_Generator">dataset</a> / <a href="https://iolfcv.github.io/">project page</a> / <a href="https://www.youtube.com/watch?v=0lybuew8Lik&t=3860s">video</a></p>
                </div>

            </div>
            </div>

            <hr>

            <div class="publication">
            <div class="row justify-content-center mb-2">
                <div class="col-auto p-0">
                    <img src="img/pub/chen_cvpr_2019.png" class="img-fluid" style="max-width: 150px" alt="...">
                </div>

                <div class="col-8 py-0 ">
                    <p><b>Unsupervised 3D Pose Estimation with Geometric Self-supervision</b></a><br>
                    <p>Utilizing adversarial learning to estimate 3D human pose without 3D supervision.</p>
                    <p><a href="https://scholar.google.com/citations?user=GlZioF6IAMYC&hl=en">Ching-Hang Chen</a>, <a href="https://scholar.google.com/citations?user=GaSWCoUAAAAJ&hl=en">Ambrish Tyagi</a>, <a href="https://scholar.google.com/citations?user=Q3puGtcAAAAJ&hl=en">Amit Agrawal</a>, <a href="https://scholar.google.com/citations?user=iYipS7kAAAAJ&hl=en">Dylan Drover</a>, <b>Stefan Stojanov</b>, <a href="https://rehg.org/">James M. Rehg</a></p>
                    <p>CVPR 2019 - Poster</p>
                    <p><a href="https://arxiv.org/abs/1904.04812">arxiv</a> </p>
                </div>

            </div>
            </div>


        </div>
        
        <div class="container-md p-2 my-3 border text-right small">
            Design inspired by the websites of <a href="https://gkioxari.github.io/">Georgia Gkioxari</a> and <a href="https://jonbarron.info/">Jon Barron</a>
        </div>

 
    </body>
    
</html>
