<!DOCTYPE html>
<html lang="en">
    <head>

        <title>Deep Object Patch Encodings</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="../bootstrap/css/bootstrap.min.css">
        <link rel="stylesheet" type="text/css" href="../main.css">
        <link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Lato">
    
    </head>
    <body>
    
        <script src="jquery-3.5.1.min.js"></script>
        <script src="../bootstrap/js/bootstrap.min.js"></script>
         
        <div class="container-md my-3 border py-4">
            <div class="row justify-content-center">
                <h2 class="text-center">Learning Dense Object Descriptors from Multiple <br> Views for Low-shot Category Generalization</h2>
            </div>

            <div class="row justify-content-center py-1">
                <h5 class="text-center"> <a href="https://sstojanov.github.io">Stefan Stojanov</a>, <a href="https://anhthai1997.wordpress.com/">Anh Thai</a>, <a href="https://zixuanh.com/">Zixuan Huang</a>, <a href="https://rehg.org/">James M. Rehg</a> </h5>
            </div>
            <div class="row justify-content-center">
                <h5 class="text-center"> Georgia Institute of Technology </h5>
            </div>
            
            <div class="row justify-content-center py-1">
                <h5 class="text-center"> <a href="https://openreview.net/pdf?id=KJemAi9fymT">paper</a> | <a href="https://github.com/rehg-lab/dope_selfsup">code</a> | <a href="https://rehg.org/">poster</a> </h5>
            </div>

            <div class="row justify-content-center">
                <div class="col-8 py-1">
                    <p>A hallmark of the deep learning era for computer vision is the successful use of large-scale labeled datasets to train feature representations for tasks ranging from object recognition and semantic segmentation to optical flow estimation and novel view synthesis of 3D scenes. In this work, we aim to learn dense discriminative object representations for low-shot category recognition <em>without</em> requiring any category labels. To this end, we propose Deep Object Patch Encodings (DOPE), which can be trained from multiple views of object instances without any category or semantic object part labels. To train DOPE, we assume access to sparse depths, foreground masks and known cameras, to obtain pixel-level correspondences between views of an object, and use this to formulate a self-supervised learning task to learn discriminative object patches. We find that DOPE can directly be used for low-shot classification of novel categories using local-part matching, and is competitive with and outperforms supervised and self-supervised learning baselines.</p>
                </div>
            </div>
            
            <div class="row justify-content-center py-1">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/qaArkLiiymk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
           
        </div>

        </div>
 
    </body>
    
</html>
